{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de476654",
   "metadata": {},
   "source": [
    "# Documentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a05caa",
   "metadata": {},
   "source": [
    "##  Q1) Which techniques you have used while cleaning the data if you have cleaned it?\n",
    "\n",
    "## I use more than one tecnique to clean data : \n",
    "\n",
    "### 1) I noticed that there are a lot of duplicates in the column (job titles). The unique job titles in data were 3890 while the entire data was more than 8000. So I performed was removing the duplicates in the data because if those duplicates are to appear in both train and test sets that would produce a false accuracy \n",
    "\n",
    "### 2) I use different text preprocessing techniques such that ( removed accented characters , lower case for all the text , Remove Special Characters , Remove Stopwords , Replace symbols by space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e838ec9",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad780a9",
   "metadata": {},
   "source": [
    "## Q2) Why have you chosen this classifier?\n",
    "\n",
    "### I working with different supervised algorithm classifer to gain the best solution and accuracy \n",
    "\n",
    "### I chose my final model to be the highest in measure (accuracy) of those different classifiers which was SVC (kernal = 'RbF') (which accuracy = 90.335 % ) . And I use it because it overcomes the space complexity problem where RBF Kernel Support Vector Machines only need to store support vectors during training and not the entire data set\n",
    "\n",
    "## -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7fd7e",
   "metadata": {},
   "source": [
    "## Q3) How do you deal with (Imbalance learning)?\n",
    "\n",
    "###  when I removed the duplicates . This semi-solved the imbalance problem between classes,And I also  add sample weights to the classifier when training to further solve this issue of imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74006b",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc510b0",
   "metadata": {},
   "source": [
    "## Q4) How can you extend the model to have better performance?\n",
    "\n",
    "### In this case I removed duplicates from data Which left me 3,890 rows to play with, and that's a very small number. Also, when you split the data into the test train, the data drops to just over 2,000 samples, so I think the performance of the model can be improved if there is more data.\n",
    "\n",
    "### And through my search for a solution to this problem, I found that it can be used pre-trained word embeddings model like Word2vec or GloVe (that bring out the semantic similarity of words that captures different facets of the meaning of a word.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2922cca",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbe9e9",
   "metadata": {},
   "source": [
    "## Q5) How do you evaluate your model? (i.e. accuracy, F1 score, Recall)\n",
    "\n",
    "### Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best.(Accuracy = TP+TN/TP+FP+FN+TN) in this model Accuracy equal 91% which is good for this model\n",
    "\n",
    "\n",
    "### Recall :  is the ratio of correctly predicted positive observations to the all observations in actual class (Recall = TP/TP+FN) . I have got recall above 0.5 which is good for this model. \n",
    "\n",
    "### F1 Score :  is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives (F1 Score = 2*(Recall * Precision) / (Recall + Precision)) \n",
    "\n",
    "### And I calculate classification_report that calculate it in the privous notebook \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4081a",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729f27c",
   "metadata": {},
   "source": [
    "## Q6) What are the limitations of your methodology or Where does your approach fail?\n",
    "\n",
    "### My limitations are mostly in the data . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2634b60",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9c8dd",
   "metadata": {},
   "source": [
    "## Referances :\n",
    "### I use the towardsdatascience website that help me alot to understand the new topics in this task and use our courses in ITI and other tutorial\n",
    "## 1 - <a href=\"https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\">towardsdatascience(Cleaning & Preprocessing Text Data)</a>\n",
    "## 2 - <a href=\"https://www.analyticsvidhya.com/blog/2020/04/how-to-deploy-machine-learning-model-flask/\">Deploy the RESTful API service Using Flask API</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c0260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
